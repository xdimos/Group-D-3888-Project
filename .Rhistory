knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(GGally)
library(dplyr)
library(tidyr)
library(ranger)
library(ggplot2)
library(readr)
library(rpart.plot) # for visual plots
library(caret)
net_measures = read.csv('network_measures.csv')
net_measures = read.csv('network_measures.csv')
head(net_measures)
predictors = net_measures %>%select(Eigenvector.Centrality, Betweenness.Centrality, Closeness.centrality, Degree)
data=net_measures%>%select(-X..Name)%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
data$essential = factor(data$essential)
head(data)
set.seed(20833)
tr_index = createDataPartition(data$essential)$Resample1
train1 <- data[tr_index, ]
train1$essential <- factor(train1$essential)
test1 <- data[-tr_index, ]
test1$essential <- factor(test1$essential)
head(test1)
# train1.1 and test 1.1
train1.1 <- train1
test1.1 <- test1
n_features <- length(setdiff(names(data), "essential"))
hyper_grid <- expand.grid(
mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
min.node.size = c(1, 3, 5),
replace = c(TRUE, FALSE),
sample.fraction = c(.5, .63, .8),
error = NA
)
for (i in seq_len(nrow(hyper_grid))) {
fit <- ranger(
formula = essential ~ .,
data = train1.1,
num.trees = n_features * 5,
mtry = hyper_grid$mtry[i],
min.node.size = hyper_grid$min.node.size[i],
replace = hyper_grid$replace[i],
sample.fraction = hyper_grid$sample.fraction[i],
verbose = FALSE,
seed = 123,
respect.unordered.factors = 'order',
)
# export OOB error
hyper_grid$error[i] <- fit$prediction.error
}
hyper_grid %>%
arrange(error) %>%
head(10)
rf_impurity <- ranger(
formula = essential ~.,
data = train1.1,
num.trees = 2000,
mtry = 1,
min.node.size = 5,
sample.fraction = .50,
replace = FALSE,
importance = "impurity",
respect.unordered.factors = "order",
verbose = FALSE,
seed = 123
)
rf_permute <- ranger(
formula = essential ~.,
data = train1.1,
num.trees = 2000,
mtry = 1,
min.node.size = 5,
sample.fraction = .50,
replace = FALSE,
importance = "permutation",
respect.unordered.factors = "order",
verbose = FALSE,
seed = 123
)
p1 <- vip::vip(rf_impurity, num_features = 10, bar = FALSE) + theme_bw()
p2 <- vip::vip(rf_permute, num_features = 10, bar = FALSE) + theme_bw()
gridExtra::grid.arrange(p1, p2, nrow = 1)
p1 <- vip::vip(rf_impurity, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
p2 <- vip::vip(rf_permute, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
gridExtra::grid.arrange(p1, p2, nrow = 1)
pred_test <- predict(rf_impurity, test1.1) # type='response' is the default - used for classification
confusionMatrix(table(pred_test$predictions, test1.1$essential))
counts = data %>%group_by(essential)%>%summarise(n=n())
(counts$n)[1]/sum(counts$n)
counts
pred_test$predictions
train1.1
rawdata=net_measures%>%%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
rawdata=net_measures%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
rawdata
train_withname = merge(rawdata, test1.1, by = c("essential","degree","eigenvector_centrality","betweenness_centrality","closeness_centrality"))
nrow(train_withname)
test_withname = merge(rawdata, test1.1, by = c("essential","degree","eigenvector_centrality","betweenness_centrality","closeness_centrality"))
nrow(test_withname)
nrow(test1.1)
data=net_measures%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
data$essential = factor(data$essential)
set.seed(20833)
tr_index = createDataPartition(data$essential)$Resample1
train1 <- data[tr_index, ]
train1$essential <- factor(train1$essential)
test1 <- data[-tr_index, ]
test1$essential <- factor(test1$essential)
head(test1)
# train1.1 and test 1.1
train1.1 <- train1
test1.1 <- test1
n_features <- length(setdiff(names(data), "essential"))
train1.1
set.seed(20833)
tr_index = createDataPartition(data$essential)$Resample1
train1 <- data[tr_index, ]
train1$essential <- factor(train1$essential)
test1 <- data[-tr_index, ]
test1$essential <- factor(test1$essential)
head(test1)
# train1.1 and test 1.1
train1.1 <- train1 %>%select(-x_name)
test1.1 <- test1%>%select(-x_name)
n_features <- length(setdiff(names(data), "essential"))
lethal_fit <- ranger(
essential~.,
data = train1.1,
mtry = floor(n_features / 3),
respect.unordered.factors = "order",
seed = 123
)
# gets the OOB error
prediction_error <- test_run$prediction.error
hyper_grid <- expand.grid(
mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
min.node.size = c(1, 3, 5),
replace = c(TRUE, FALSE),
sample.fraction = c(.5, .63, .8),
error = NA
)
for (i in seq_len(nrow(hyper_grid))) {
fit <- ranger(
formula = essential ~ .,
data = train1.1,
num.trees = n_features * 5,
mtry = hyper_grid$mtry[i],
min.node.size = hyper_grid$min.node.size[i],
replace = hyper_grid$replace[i],
sample.fraction = hyper_grid$sample.fraction[i],
verbose = FALSE,
seed = 123,
respect.unordered.factors = 'order',
)
# export OOB error
hyper_grid$error[i] <- fit$prediction.error
}
hyper_grid %>%
arrange(error) %>%
head(10)
rf_impurity <- ranger(
formula = essential ~.,
data = train1.1,
num.trees = 2000,
mtry = 1,
min.node.size = 5,
sample.fraction = .50,
replace = FALSE,
importance = "impurity",
respect.unordered.factors = "order",
verbose = FALSE,
seed = 123
)
rf_permute <- ranger(
formula = essential ~.,
data = train1.1,
num.trees = 2000,
mtry = 1,
min.node.size = 5,
sample.fraction = .50,
replace = FALSE,
importance = "permutation",
respect.unordered.factors = "order",
verbose = FALSE,
seed = 123
)
p1 <- vip::vip(rf_impurity, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
p2 <- vip::vip(rf_permute, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
gridExtra::grid.arrange(p1, p2, nrow = 1)
pred_test <- predict(rf_impurity, test1.1) # type='response' is the default - used for classification
confusionMatrix(table(pred_test$predictions, test1.1$essential))
counts = data %>%group_by(essential)%>%summarise(n=n())
(counts$n)[1]/sum(counts$n)
nrow(test1.1)
test1.1
test1
pred_test$predictions
preds = pred_test$predictions
output_preds$predicted_lethality = preds
test1$predicted_lethality = preds
test1
head(test1)
test1%>%mutate(acc=(predicted_lethality==essential))
sum((test1%>%mutate(acc=(predicted_lethality==essential)))$acc)/nrow(test1)
test1=test1%>%mutate(acc=(predicted_lethality==essential)))
test1=test1%>%mutate(acc=(predicted_lethality==essential))
write.csv(test1,'predicted_essential.csv')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(GGally)
library(dplyr)
library(tidyr)
library(ranger)
library(ggplot2)
library(readr)
library(rpart.plot) # for visual plots
library(caret)
net_measures = read.csv('network_measures.csv')
head(net_measures)
predictors = net_measures %>%select(Eigenvector.Centrality, Betweenness.Centrality, Closeness.centrality, Degree)
ggpairs(predictors)
data=net_measures%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
data$essential = factor(data$essential)
head(data)
set.seed(20833)
tr_index = createDataPartition(data$essential)$Resample1
train1 <- data[tr_index, ]
train1$essential <- factor(train1$essential)
test1 <- data[-tr_index, ]
test1$essential <- factor(test1$essential)
head(test1)
# train1.1 and test 1.1
train1.1 <- train1 %>%select(-x_name)
test1.1 <- test1%>%select(-x_name)
n_features <- length(setdiff(names(data), "essential"))
train1.1
lethal_fit <- ranger(
essential~.,
data = train1.1,
mtry = floor(n_features / 3),
respect.unordered.factors = "order",
seed = 123
)
# gets the OOB error
prediction_error <- test_run$prediction.error
lethal_fit <- ranger(
essential~.,
data = train1.1,
mtry = floor(n_features / 3),
respect.unordered.factors = "order",
seed = 123
)
# gets the OOB error
prediction_error <- test1.1$prediction.error
prediction_error
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(GGally)
library(dplyr)
library(tidyr)
library(ranger)
library(ggplot2)
library(readr)
library(rpart.plot) # for visual plots
library(caret)
net_measures = read.csv('network_measures.csv')
head(net_measures)
predictors = net_measures %>%select(Eigenvector.Centrality, Betweenness.Centrality, Closeness.centrality, Degree)
ggpairs(predictors)
data=net_measures%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
data$essential = factor(data$essential)
head(data)
set.seed(20833)
tr_index = createDataPartition(data$essential)$Resample1
train1 <- data[tr_index, ]
train1$essential <- factor(train1$essential)
test1 <- data[-tr_index, ]
test1$essential <- factor(test1$essential)
head(test1)
# train1.1 and test 1.1
train1.1 <- train1 %>%select(-x_name)
test1.1 <- test1%>%select(-x_name)
n_features <- length(setdiff(names(data), "essential"))
train1.1
lethal_fit <- ranger(
essential~.,
data = train1.1,
mtry = floor(n_features / 3),
respect.unordered.factors = "order",
seed = 123
)
# gets the OOB error
prediction_error <- test1.1$prediction.error
prediction_error
hyper_grid <- expand.grid(
mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
min.node.size = c(1, 3, 5),
replace = c(TRUE, FALSE),
sample.fraction = c(.5, .63, .8),
error = NA
)
for (i in seq_len(nrow(hyper_grid))) {
fit <- ranger(
formula = essential ~ .,
data = train1.1,
num.trees = n_features * 5,
mtry = hyper_grid$mtry[i],
min.node.size = hyper_grid$min.node.size[i],
replace = hyper_grid$replace[i],
sample.fraction = hyper_grid$sample.fraction[i],
verbose = FALSE,
seed = 123,
respect.unordered.factors = 'order',
)
# export OOB error
hyper_grid$error[i] <- fit$prediction.error
}
hyper_grid %>%
arrange(error) %>%
head(10)
rf_impurity <- ranger(
formula = essential ~.,
data = train1.1,
num.trees = 2000,
mtry = 1,
min.node.size = 5,
sample.fraction = .50,
replace = FALSE,
importance = "impurity",
respect.unordered.factors = "order",
verbose = FALSE,
seed = 123
)
rf_permute <- ranger(
formula = essential ~.,
data = train1.1,
num.trees = 2000,
mtry = 1,
min.node.size = 5,
sample.fraction = .50,
replace = FALSE,
importance = "permutation",
respect.unordered.factors = "order",
verbose = FALSE,
seed = 123
)
p1 <- vip::vip(rf_impurity, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
p2 <- vip::vip(rf_permute, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
gridExtra::grid.arrange(p1, p2, nrow = 1)
pred_test <- predict(rf_impurity, test1.1) # type='response' is the default - used for classification
confusionMatrix(table(pred_test$predictions, test1.1$essential))
counts = data %>%group_by(essential)%>%summarise(n=n())
(counts$n)[1]/sum(counts$n)
preds = pred_test$predictions
test1$predicted_lethality = preds
test1=test1%>%mutate(acc=(predicted_lethality==essential))
write.csv(test1,'predicted_essential.csv')
cm = confusionMatrix(table(pred_test$predictions, test1.1$essential))
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title('CONFUSION MATRIX', cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Class1', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Class2', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Class1', cex=1.2, srt=90)
text(140, 335, 'Class2', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
# add in the accuracy information
text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
draw_confusion_matrix(cm)
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title('CONFUSION MATRIX', cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Non-essential', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Essential', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Non-essential', cex=1.2, srt=90)
text(140, 335, 'Essential', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
# add in the accuracy information
text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
draw_confusion_matrix(cm)
