---
title: "MATH3888_report"
author: '500487424'
date: "19/10/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(janitor)
library(GGally)
library(dplyr)
library(tidyr)
library(ranger)
library(ggplot2)
library(readr)
library(rpart.plot) # for visual plots
library(caret)
```


```{r}
net_measures = read.csv('network_measures.csv')
```

```{r}
head(net_measures)
```
```{r}
predictors = net_measures %>%select(Eigenvector.Centrality, Betweenness.Centrality, Closeness.centrality, Degree)
```

```{r}
ggpairs(predictors)
```

```{r}
data=net_measures%>%clean_names()%>%mutate(essential = ifelse(essential==" True",1,0))
```

```{r}
data$essential = factor(data$essential)
```

```{r}
head(data)
```


```{r}
set.seed(20833)
tr_index = createDataPartition(data$essential)$Resample1
train1 <- data[tr_index, ] 
train1$essential <- factor(train1$essential)
test1 <- data[-tr_index, ]
test1$essential <- factor(test1$essential)
head(test1)
# train1.1 and test 1.1
train1.1 <- train1 %>%select(-x_name)
test1.1 <- test1%>%select(-x_name)

n_features <- length(setdiff(names(data), "essential"))

```
```{r}
train1.1
```



#test run
```{r}
lethal_fit <- ranger(
  essential~.,
  data = train1.1,
  mtry = floor(n_features / 3),
  respect.unordered.factors = "order",
  seed = 123
)
# gets the OOB error
prediction_error <- test1.1$prediction.error
prediction_error
```


# make grid for optimal parameters
```{r}
hyper_grid <- expand.grid(
  mtry = floor(n_features * c(.05, .15, .25, .333, .4)),
  min.node.size = c(1, 3, 5), 
  replace = c(TRUE, FALSE),
  sample.fraction = c(.5, .63, .8),
  error = NA
)
for (i in seq_len(nrow(hyper_grid))) {
  fit <- ranger(
    formula = essential ~ .,
    data = train1.1, 
    num.trees = n_features * 5,
    mtry = hyper_grid$mtry[i],
    min.node.size = hyper_grid$min.node.size[i],
    replace = hyper_grid$replace[i],
    sample.fraction = hyper_grid$sample.fraction[i],
    verbose = FALSE,
    seed = 123,
    respect.unordered.factors = 'order',
  )
  
  # export OOB error
  hyper_grid$error[i] <- fit$prediction.error
}
hyper_grid %>%
  arrange(error) %>%
  head(10)
```
optimal out of bag error is found by settin mtry=1,node size = 5, replace = FALSE, samp = 0.5
```{r}
rf_impurity <- ranger(
  formula = essential ~., 
  data = train1.1,
  num.trees = 2000,
  mtry = 1,
  min.node.size = 5,
  sample.fraction = .50,
  replace = FALSE,
  importance = "impurity",
  respect.unordered.factors = "order",
  verbose = FALSE,
  seed = 123
)
rf_permute <- ranger(
  formula = essential ~., 
  data = train1.1,
  num.trees = 2000,
  mtry = 1,
  min.node.size = 5,
  sample.fraction = .50,
  replace = FALSE,
  importance = "permutation",
  respect.unordered.factors = "order",
  verbose = FALSE,
  seed = 123
)
```

```{r}
p1 <- vip::vip(rf_impurity, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()
p2 <- vip::vip(rf_permute, num_features = 10, bar = FALSE,include_type=TRUE) + theme_bw()

gridExtra::grid.arrange(p1, p2, nrow = 1)
```


```{r}
pred_test <- predict(rf_impurity, test1.1) # type='response' is the default - used for classification
confusionMatrix(table(pred_test$predictions, test1.1$essential))
```

Specificity really low so very bad at recognising when a node is not lethal! But good at recognising that a node is lethal.

Check ut our class imbalance:

```{r}
counts = data %>%group_by(essential)%>%summarise(n=n())
(counts$n)[1]/sum(counts$n)
```
 78% of data is nonlethal so we have a problem ! imbalanced data.
 
```{r}
preds = pred_test$predictions
```


 
```{r}
test1$predicted_lethality = preds
```

```{r}
test1=test1%>%mutate(acc=(predicted_lethality==essential))
```

```{r}
cm = confusionMatrix(table(pred_test$predictions, test1.1$essential))
```


```{r}

draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'Non-essential', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'Essential', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'Non-essential', cex=1.2, srt=90)
  text(140, 335, 'Essential', cex=1.2, srt=90)

  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  
```

```{r}
draw_confusion_matrix(cm)
```


Presentation caret package code from here: https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package



```{r}
#write.csv(test1,'predicted_essential.csv')
```


